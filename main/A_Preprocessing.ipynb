{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nauteur:Alexandre\\ndate:2024/09/03\\n\\nPreprocessing des données pur les rendre utilisable par l'algorithme de machine learning\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "auteur:Alexandre\n",
    "date:2024/09/03\n",
    "\n",
    "Preprocessing des données pur les rendre utilisable par l'algorithme de machine learning\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pp\n",
    "import params as prm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elections législatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70102, 190) (61615, 55)\n"
     ]
    }
   ],
   "source": [
    "data_1 = pp.load_data(file_name=f\"{prm.dataset_1er_tour}.csv\")\n",
    "data_2 = pp.load_data(file_name=f\"{prm.dataset_2nd_tour}.csv\")\n",
    "print(data_1.shape, data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the already preprocessed dataset !\n",
      "Loading the already preprocessed dataset !\n",
      "(70102, 25) (61615, 20)\n"
     ]
    }
   ],
   "source": [
    "df_1, encodeur = pp.prepare(data_1, name=prm.dataset_1er_tour, encodeur=None)\n",
    "df_2, encodeur = pp.prepare(data_2, name=prm.dataset_2nd_tour, encodeur=encodeur)\n",
    "print(df_1.shape, df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cleaning phase has already been completed !\n",
      "(61593, 23) (61593, 18)\n"
     ]
    }
   ],
   "source": [
    "df_1f, df_2f = pp.clear(\n",
    "    df_1, df_2, \n",
    "    name1=prm.dataset_1er_tour, \n",
    "    name2=prm.dataset_2nd_tour\n",
    ")\n",
    "print(df_1f.shape, df_2f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessing phase has already been completed !\n",
      "(38932, 13)\n"
     ]
    }
   ],
   "source": [
    "path_pp_adresses = os.path.join(prm.datasets_pp_path, \"communes-departement-region.csv\")\n",
    "\n",
    "if os.path.exists(path_pp_adresses):\n",
    "\n",
    "    print(\"The preprocessing phase has already been completed !\")\n",
    "    adresses = pd.read_csv(\n",
    "        path_pp_adresses\n",
    "    )\n",
    "\n",
    "else :\n",
    "\n",
    "    print(\"We have to drop the NaN !\")\n",
    "    \n",
    "    # Chargement des données\n",
    "    adresses = pd.read_csv(\n",
    "        os.path.join(prm.datasets_raw_path, \"communes-departement-region.csv\")\n",
    "    )\n",
    "\n",
    "    # Drop les colonnes et des lignes ayant des NaN\n",
    "    col_drop = adresses.keys()[adresses.isna().sum() / adresses.shape[0] > 0.90]\n",
    "    long_drop = adresses.index[adresses[\"longitude\"].isna()]\n",
    "    lat_drop = adresses.index[adresses[\"latitude\"].isna()]\n",
    "    ind_drop = np.unique(np.concatenate([long_drop,lat_drop]))\n",
    "\n",
    "    adresses = adresses.drop(index=ind_drop, columns=col_drop)\n",
    "    \n",
    "\n",
    "    adresses.to_csv(path_pp_adresses, index=False)\n",
    "print(adresses.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informations Socio-Economiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessing phase has already been completed !\n",
      "(139168, 21)\n"
     ]
    }
   ],
   "source": [
    "file_name = \"fr-en-dnb-par-etablissement.csv\"\n",
    "path_pp_dnb = os.path.join(prm.datasets_pp_path, file_name)\n",
    "\n",
    "if os.path.exists(path_pp_dnb):\n",
    "    \n",
    "    print(\"The preprocessing phase has already been completed !\")\n",
    "    dnb_resultats = pd.read_csv(\n",
    "        path_pp_dnb,\n",
    "        low_memory=False\n",
    "    )\n",
    "\n",
    "else :\n",
    "\n",
    "    print(\"We have to drop the NaN !\")\n",
    "    \n",
    "    # Chargement des données\n",
    "    dnb_resultats = pd.read_csv(\n",
    "        os.path.join(prm.datasets_raw_path, file_name),\n",
    "        sep=\";\"\n",
    "    )\n",
    "\n",
    "    # Drop des lignes ne voulant rien dire\n",
    "    dnb_resultats = dnb_resultats[dnb_resultats[\"code_departement\"] != '-']\n",
    "    \n",
    "    # Drop les colonnes et des lignes ayant des NaN\n",
    "    dnb_resultats = dnb_resultats[dnb_resultats[\"patronyme\"].notna()].sort_values(by=\"code_departement\")\n",
    "    dnb_resultats.to_csv(path_pp_dnb, index=False)\n",
    "\n",
    "print(dnb_resultats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have to drop the NaN !\n",
      "(983, 8)\n"
     ]
    }
   ],
   "source": [
    "file_name = \"fr-en-boursiers-par-departement.csv\"\n",
    "path_pp_bourse = os.path.join(prm.datasets_pp_path, file_name)\n",
    "\n",
    "if os.path.exists(path_pp_bourse):\n",
    "    \n",
    "    print(\"The preprocessing phase has already been completed !\")\n",
    "    dnb_resultats = pd.read_csv(\n",
    "        path_pp_bourse\n",
    "    )\n",
    "\n",
    "else :\n",
    "\n",
    "    print(\"We have to drop the NaN !\")\n",
    "    \n",
    "    # Chargement des données\n",
    "    boursier_departement = pd.read_csv(\n",
    "        os.path.join(prm.datasets_raw_path, file_name),\n",
    "        sep=\";\"\n",
    "    )\n",
    "    \n",
    "    # Drop les colonnes et des lignes ayant des NaN\n",
    "    boursier_departement = boursier_departement.drop(\n",
    "        columns=boursier_departement.keys()[boursier_departement.isna().sum()/boursier_departement.shape[0] > 0]\n",
    "        ).sort_values(by=\"numero_departement\")\n",
    "    boursier_departement.to_csv(path_pp_bourse, index=False)\n",
    "\n",
    "print(boursier_departement.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-09-11T20:56:18.355836+02:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 8.24.0\n",
      "\n",
      "Compiler    : MSC v.1938 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : AMD64 Family 25 Model 116 Stepping 1, AuthenticAMD\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prm.WaTer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
